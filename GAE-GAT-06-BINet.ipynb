{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99177d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrow\n",
    "import socket\n",
    "from sqlalchemy.orm import Session\n",
    "from tqdm import tqdm\n",
    "\n",
    "from april import Evaluator\n",
    "from april.anomalydetection import *\n",
    "from april.database import EventLog\n",
    "from april.database import Model\n",
    "from april.database import get_engine\n",
    "from april.dataset import Dataset\n",
    "from april.fs import DATE_FORMAT\n",
    "from april.fs import get_event_log_files\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_member(a, b):   \n",
    "    a_set = set(a)\n",
    "    b_set = set(b)     \n",
    "    # check length\n",
    "    if len(a_set.intersection(b_set)) > 0:\n",
    "        return(a_set.intersection(b_set)) \n",
    "    else:\n",
    "        return(\"no common elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_save(dataset_name, ad, ad_kwargs=None, fit_kwargs=None):\n",
    "    if ad_kwargs is None:\n",
    "        ad_kwargs = {}\n",
    "    if fit_kwargs is None:\n",
    "        fit_kwargs = {}\n",
    "\n",
    "    # Save start time\n",
    "    start_time = arrow.now()\n",
    "\n",
    "    # Dataset\n",
    "    dataset = Dataset(dataset_name)\n",
    "\n",
    "    # AD\n",
    "    ad = ad(**ad_kwargs)\n",
    "\n",
    "    # Train and save\n",
    "    ad.fit(dataset, **fit_kwargs)\n",
    "    file_name = f'{dataset_name}_{ad.abbreviation}_{start_time.format(DATE_FORMAT)}'\n",
    "    model_file = ad.save(file_name)\n",
    "\n",
    "    # Save end time\n",
    "    end_time = arrow.now()\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b309273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_att (event_data, final_scores, alpha):\n",
    "    number_cases = len(event_data)\n",
    "    num_events = 0\n",
    "    for i in range (number_cases):\n",
    "        num_events += len(event_data[i])\n",
    "    temp = np.sum(final_scores, axis=0)\n",
    "    threshold_arr = np.sum(temp, axis=0)\n",
    "    threshold_arr = alpha*threshold_arr/num_events\n",
    "    return threshold_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = sorted([e.name for e in get_event_log_files() if e.p == 0.3])\n",
    "ads = [dict(ad=BINetv2, fit_kwargs=dict(epochs=50, batch_size=100))]\n",
    "for ad in ads:\n",
    "    model = [fit_and_save(d, **ad) for d in tqdm(datasets, desc=ad['ad'].name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f92a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = sorted([e.name for e in get_event_log_files()])\n",
    "ads = [dict(ad=BINetv2, fit_kwargs=dict(epochs=50, batch_size=100))]\n",
    "for ad in ads:\n",
    "    model = [fit_and_save(d, **ad) for d in tqdm(datasets, desc=ad['ad'].name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de2bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n",
    "p1 = Evaluator(r'C:\\Users\\ASUS\\.out\\models\\wide-0.1-1_binetv2_20220711-231436.646890.model').result\n",
    "print(dir(Evaluator))\n",
    "print(p1)\n",
    "final_scores = p1.scores\n",
    "print(final_scores.shape)\n",
    "print(type(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_log_path = r'D:\\Final master thesis evaluation\\datasets\\5\\wide-0.1-1.xes'\n",
    "event_data = xes_importer.apply(event_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_csv = pd.read_csv(r'D:\\Final master thesis evaluation\\wide-five\\wide-0.1-1.csv')\n",
    "loss_df_path  = r'D:\\Final master thesis evaluation\\wide-five\\binet_loss.pt'\n",
    "label_csv.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "label_csv[\"case_id\"] = pd.to_numeric(label_csv[\"case_id\"])\n",
    "label_csv.case_id.astype(str).astype(int)\n",
    "label_csv.label.astype(str)\n",
    "test_csv = label_csv.loc[label_csv['case_id'] > 12000]\n",
    "label_csv1 = test_csv.loc[test_csv['label']!= 'normal']\n",
    "M = list(label_csv1['case_id'])\n",
    "print(len(test_csv))\n",
    "print(len(label_csv1))\n",
    "#print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_array = threshold_att(event_data, final_scores, alpha = 1)\n",
    "print(threshold_array)\n",
    "case_id_list = []\n",
    "max_ratio_list = []\n",
    "for i in range (12000, final_scores.shape[0]):\n",
    "    max_loss_ratio = 0\n",
    "    for j in range (final_scores.shape[1]):\n",
    "        for k in range (final_scores.shape[2]):\n",
    "            max_loss_ratio = max(max_loss_ratio, final_scores[i][j][k]/threshold_array[k])\n",
    "    case_id_list.append(i+1)\n",
    "    max_ratio_list.append(max_loss_ratio)\n",
    "BINet_dictionary = {'case_id': case_id_list, 'max_ratio': max_ratio_list}\n",
    "loss_df = pd.DataFrame(BINet_dictionary)\n",
    "loss_df = pd.merge(loss_df, test_csv, on=[\"case_id\"])\n",
    "loss_df.to_pickle(loss_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5360da",
   "metadata": {},
   "outputs": [],
   "source": [
    "suspicious_csv = loss_df.loc[loss_df['max_ratio'] > 3.85]\n",
    "print(len(suspicious_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d7373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "suspicious_ids = list(suspicious_csv['case_id'])\n",
    "print(len(list(common_member(suspicious_ids, M))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c689468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_array = threshold_att(event_data, final_scores, alpha = 5.51)\n",
    "log_prediction = []\n",
    "log_prediction_index = []\n",
    "for i in range (12000, final_scores.shape[0]):\n",
    "    case_prediction = 0\n",
    "    for j in range (final_scores.shape[1]):\n",
    "        for k in range (final_scores.shape[2]):\n",
    "            if final_scores[i][j][k] > threshold_array[k]:\n",
    "                case_prediction = 1\n",
    "    log_prediction.append(case_prediction)\n",
    "    if case_prediction == 1:\n",
    "        log_prediction_index.append(i+1)\n",
    "log_prediction_array = np.array(log_prediction)\n",
    "print(threshold_array)\n",
    "print(np.sum(log_prediction_array))\n",
    "#print(log_prediction_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2c2a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(common_member(log_prediction_index, M))\n",
    "print(len(list(common_member(log_prediction_index, M))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
