{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b6785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os.path as osp\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import random\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.objects.log.exporter.xes import exporter as xes_exporter\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.algo.filtering.log.attributes import attributes_filter\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import NNConv\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa3cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_path = r'D:\\Final master thesis evaluation\\datasets'\n",
    "log_pattern = r'D:\\Final master thesis evaluation\\datasets\\*.json'\n",
    "logs = glob.glob(log_pattern)\n",
    "allfiles = [f for f in listdir(interest_path) if isfile(join(interest_path, f))]\n",
    "allfilescopy = copy.deepcopy(allfiles)\n",
    "allfiles_str = sorted(list({x.replace('.json', '.xes') for x in allfiles}))\n",
    "label_str = sorted(list({x.replace('.json', '.csv') for x in allfilescopy}))\n",
    "def getListofallkeys(dict):      \n",
    "    return list(dict.keys())\n",
    "log_counter = 0\n",
    "for log in logs:\n",
    "    # Opening JSON file\n",
    "    f = open(log,)\n",
    "    # returns JSON object as a dictionary\n",
    "    data = json.load(f) \n",
    "    # Closing file\n",
    "    f.close()\n",
    "    #print(type(data))\n",
    "    #print(getListofallkeys(data))\n",
    "    all_case = data.get('cases', None)\n",
    "    num_cases = len(all_case)\n",
    "    #print(type(all_case), num_cases, all_case[0], type(all_case[0]))\n",
    "    temp_list = all_case[0].get('events', None)\n",
    "    att_dic = temp_list[0].get('attributes', None)\n",
    "    list_of_attributes = getListofallkeys(att_dic)\n",
    "    event_list_to_df = []\n",
    "    case_list_to_df = []\n",
    "    normal_cases = 0\n",
    "    anomalous_cases = 0\n",
    "    timestamp = True\n",
    "    for i in range (num_cases):\n",
    "        label_hint = all_case[i].get('attributes', None)\n",
    "        label = label_hint.get('label', None)\n",
    "        if label != 'normal':\n",
    "            anomalous_cases += 1\n",
    "        else:\n",
    "            normal_cases += 1\n",
    "        events_hint = all_case[i].get('events', None)\n",
    "        num_events = len(events_hint)\n",
    "        case_id = all_case[i].get('id', None)\n",
    "        for j in range (num_events):\n",
    "            event_activity = events_hint[j].get('name', None)\n",
    "            event_timestamp = events_hint[j].get('timestamp', None)\n",
    "            event_timestamp_end = events_hint[j].get('timestamp_end', None)\n",
    "            event_user_hint = events_hint[j].get('attributes', None)\n",
    "            if len(list_of_attributes) == 4:\n",
    "                event_user = event_user_hint.get('user', None)\n",
    "                event_day = event_user_hint.get('day', None)\n",
    "                event_country = event_user_hint.get('country', None)\n",
    "                event_company = event_user_hint.get('company', None)\n",
    "                event_dic = {'case_id' : case_id, 'concept:name' : event_activity , 'timestamp' : event_timestamp,\n",
    "                             'timestamp_end': event_timestamp_end, 'user' : event_user, 'day' : event_day,\n",
    "                            'country' : event_country, 'company': event_company}\n",
    "            elif len(list_of_attributes) == 3:\n",
    "                event_user = event_user_hint.get('user', None)\n",
    "                event_day = event_user_hint.get('day', None)\n",
    "                event_country = event_user_hint.get('country', None)\n",
    "                event_dic = {'case_id' : case_id, 'concept:name' : event_activity , 'timestamp' : event_timestamp,\n",
    "                             'timestamp_end': event_timestamp_end, 'user' : event_user, 'day' : event_day,\n",
    "                            'country' : event_country}\n",
    "            elif len(list_of_attributes) == 2:\n",
    "                event_user = event_user_hint.get('user', None)\n",
    "                event_day = event_user_hint.get('day', None)\n",
    "                event_dic = {'case_id' : case_id, 'concept:name' : event_activity , 'timestamp' : event_timestamp,\n",
    "                             'timestamp_end': event_timestamp_end, 'user' : event_user, 'day' : event_day}\n",
    "            else:\n",
    "                event_user = event_user_hint.get('user', None)\n",
    "                event_dic = {'case_id' : case_id, 'concept:name' : event_activity , 'timestamp' : event_timestamp,\n",
    "                             'timestamp_end': event_timestamp_end, 'user' : event_user}                \n",
    "            event_list_to_df.append(event_dic)   \n",
    "        label_dic = {'case_id' : case_id, 'label' : label}\n",
    "        case_list_to_df.append(label_dic)\n",
    "    event_df = pd.DataFrame.from_dict(event_list_to_df)\n",
    "    label_df = pd.DataFrame.from_dict(case_list_to_df)\n",
    "    if event_df['timestamp'].isnull().all():\n",
    "        timestamp = False\n",
    "    event_df.dropna(axis=1, how='all', inplace=True)\n",
    "    print(normal_cases, anomalous_cases, timestamp)\n",
    "    parameters = {log_converter.Variants.TO_EVENT_LOG.value.Parameters.CASE_ID_KEY: 'case_id'}\n",
    "    log = log_converter.apply(event_df, parameters=parameters, variant=log_converter.Variants.TO_EVENT_LOG)\n",
    "    filename = allfiles_str[log_counter]\n",
    "    full_filename = os.path.join(interest_path, filename)\n",
    "    xes_exporter.apply(log, full_filename)\n",
    "    filename = label_str[log_counter]\n",
    "    full_filename = os.path.join(interest_path, filename)\n",
    "    label_df.to_csv(full_filename)\n",
    "    log_counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
